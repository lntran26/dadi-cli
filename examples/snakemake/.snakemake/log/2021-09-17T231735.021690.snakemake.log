Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job stats:
job                    count    min threads    max threads
-------------------  -------  -------------  -------------
all                        1              1              1
dadi_bestfit_dm            1              1              1
dadi_generate_cache        1              8              8
dadi_infer_dm              1              8              8
total                      4              1              8

Select jobs to execute...

[Fri Sep 17 23:17:35 2021]
rule dadi_infer_dm:
    input: 1KG.YRI.synonymous.snps.unfold.fs
    output: 1KG.YRI.three_epoch_1d.demo.params.InferDM.opts.0
    jobid: 3
    threads: 8
    resources: tmpdir=/tmp

Terminating processes on user request, this might take some time.
[Fri Sep 17 23:17:44 2021]
Error in rule dadi_infer_dm:
    jobid: 3
    output: 1KG.YRI.three_epoch_1d.demo.params.InferDM.opts.0
    shell:
        dadi-cli InferDM --fs 1KG.YRI.synonymous.snps.unfold.fs --model three_epoch_1d --misid --p0 1 1 1 1 .5 --ubounds 10 10 10 10 1 --lbounds 10e-3 10e-3 10e-3 10e-3 10e-5 --output-prefix 1KG.YRI.three_epoch_1d.demo.params --thread 30
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job dadi_infer_dm since they might be corrupted:
1KG.YRI.three_epoch_1d.demo.params.InferDM.opts.0
Complete log: /home/kaiser/Documents/projects/dadi-cli/examples/snakemake/.snakemake/log/2021-09-17T231735.021690.snakemake.log
