Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job stats:
job                    count    min threads    max threads
-------------------  -------  -------------  -------------
all                        1              1              1
dadi_generate_cache        1              8              8
total                      2              1              8

Select jobs to execute...

[Fri Sep 17 22:08:08 2021]
rule dadi_generate_cache:
    input: 1KG.YRI.three_epoch_1d.demo.params.InferDM.bestfits
    output: 1KG.YRI.three_epoch.sel.spectra.bpkl
    jobid: 1
    threads: 8
    resources: tmpdir=/tmp

[Fri Sep 17 22:08:09 2021]
Error in rule dadi_generate_cache:
    jobid: 1
    output: 1KG.YRI.three_epoch.sel.spectra.bpkl
    shell:
        dadi-cli GenerateCache --model three_epoch --demo-popt 1KG.YRI.three_epoch_1d.demo.params.InferDM.bestfits --sample-size 216 --output 1KG.YRI.three_epoch.sel.spectra.bpkl --mp --misid
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/kaiser/Documents/projects/dadi-cli/examples/snakemake/.snakemake/log/2021-09-17T220808.310519.snakemake.log
