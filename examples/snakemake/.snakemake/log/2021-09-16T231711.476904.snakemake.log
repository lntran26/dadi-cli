Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job stats:
job                    count    min threads    max threads
-------------------  -------  -------------  -------------
all                        1              1              1
dadi_generate_cache        1              1              1
total                      2              1              1

Select jobs to execute...

[Thu Sep 16 23:17:11 2021]
rule dadi_generate_cache:
    input: 1KG.YRI.three_epoch_1d.demo.params.InferDM.bestfits
    output: 1KG.YRI.three_epoch.sel.spectra.bpkl
    jobid: 1
    resources: tmpdir=/tmp

[Thu Sep 16 23:17:12 2021]
Error in rule dadi_generate_cache:
    jobid: 1
    output: 1KG.YRI.three_epoch.sel.spectra.bpkl
    shell:
        dadi-cli GenerateCache --model three_epoch --demo-popt <(grep -v "#" 1KG.YRI.three_epoch_1d.demo.params.InferDM.bestfits | head -1 | awk '{print $2"	"$3"	"$4"	"$5}') --sample-size 216 --output 1KG.YRI.three_epoch.sel.spectra.bpkl --mp
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/kaiser/Documents/projects/dadi-cli/examples/snakemake/.snakemake/log/2021-09-16T231711.476904.snakemake.log
